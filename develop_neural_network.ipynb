{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cHqo6b1_Bzk"
      },
      "source": [
        "# Implementing a Neural Network\n",
        "\n",
        "This notebook contains testing code todevelop a neural network by implementing the forward pass and backpropagation algorithm in the `models/neural_net.py` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTt_CiWh_Bzm",
        "outputId": "0fdf5886-6776-407f-8290-b9da1d5ce198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# from models.neural_net import NeuralNetwork\n",
        "from models.neural_net_solution import NeuralNetwork\n",
        "\n",
        "\n",
        "# For auto-reloading external modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def rel_error(x, y):\n",
        "    \"\"\"Returns relative error\"\"\"\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5X9DO-5_Bzn"
      },
      "source": [
        "The cell below initializes a toy dataset and corresponding model which will allow you to check your forward and backward pass by using a numeric gradient check. Note that we set a random seed for repeatable experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "358jAXcc_Bzn"
      },
      "outputs": [],
      "source": [
        "input_size = 2\n",
        "hidden_size = 10\n",
        "num_classes = 3\n",
        "num_inputs = 5\n",
        "optimizer = 'SGD'\n",
        "\n",
        "\n",
        "def init_toy_model(num_layers):\n",
        "    \"\"\"Initializing a toy model\"\"\"\n",
        "    np.random.seed(0)\n",
        "    hidden_sizes = [hidden_size] * (num_layers - 1)\n",
        "    return NeuralNetwork(input_size, hidden_sizes, num_classes, num_layers, optimizer)\n",
        "\n",
        "def init_toy_data():\n",
        "    \"\"\"Initializing a toy dataset\"\"\"\n",
        "    np.random.seed(0)\n",
        "    X = np.random.randn(num_inputs, input_size)\n",
        "    y = np.random.randn(num_inputs, num_classes)\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh_v9biP_Bzn"
      },
      "source": [
        "# Implementing forward and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjAwpT2z_Bzo"
      },
      "source": [
        "### Gradient  check\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZM47qUP_Bzo",
        "outputId": "0b953ef9-9aab-4be0-efc4-8a2502df572b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2090055637515489\n",
            "W1 max relative error: 1.000000e+00\n",
            "b1 max relative error: 4.281518e-10\n",
            "W2 max relative error: 1.000000e+00\n",
            "b2 max relative error: 6.769680e-10\n",
            "1.2469477304657224\n",
            "W1 max relative error: 1.000000e+00\n",
            "b1 max relative error: 3.926769e-09\n",
            "W2 max relative error: 1.000000e+00\n",
            "b2 max relative error: 7.907491e-10\n",
            "W3 max relative error: 1.000000e+00\n",
            "b3 max relative error: 7.659362e-11\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "from utils.gradient_check import eval_numerical_gradient\n",
        "\n",
        "X, y = init_toy_data()\n",
        "\n",
        "\n",
        "def f(W):\n",
        "    net.forward(X)\n",
        "    return net.backward(y)\n",
        "\n",
        "# print(X.shape)\n",
        "for num in [2, 3]:\n",
        "    net = init_toy_model(num)\n",
        "    net.forward(X)\n",
        "    # print(\"----\")\n",
        "    print(net.backward(y))\n",
        "    # print(net.gradients)\n",
        "    # for grads in net.gradients.keys():\n",
        "    #   print(grads, net.gradients[grads])\n",
        "    # print(\"-----\")\n",
        "    gradients = deepcopy(net.gradients)\n",
        "\n",
        "    for param_name in net.params:\n",
        "        param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
        "        print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, gradients[param_name])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
